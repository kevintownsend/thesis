\specialchapt{ABSTRACT}
%This dissertation implements a sparse matrix vector multiplication (SpMV) algorithm for FPGAs. CPUs, GPUs and FPGAs are processors that run different algorithms at different speeds. Much like how the performance of an athlete depends on the design of the course as much as it does on the particular athlete. SpMV is an interesting course in that tweaking the size and sparsity of the matrix will change who wins the race. For example, CPUs compute small matrices quickly due to the fact the matrix and vector can fit in on-chip cache. GPUs compute structured matrices quickly due to how they preprocess the matrix. Currently FPGAs compute matrices at a relatively consistent speed, but we show compressible matrices can achieve better performance. In this paper we implement an FPGA-based SpMV algorithm and use features of the course (matrix) to run faster.

There are hundreds of papers on accelerating sparse matrix vector multiplication (SpMV), however, only a handful target FPGAs. Many claim that FPGAs inherently perform inferiorly to CPUs and GPUs. FPGAs do perform inferiorly for some applications like matrix-matrix multiplication and matrix-vector multiplication. CPUs and GPUs have too much memory bandwidth and too much floating point computation power for FPGAs to compete. However, the low computations to memory operations ratio and irregular memory access of SpMV trips up both CPUs and GPUs. We see this as a leveling of the playing field for FPGAs.

Our implementation focuses on three pillars: matrix traversal, multiply-accumulator design, and matrix compression. First, Most SpMV impementations traverse the matrix in row-major order, but we mix column and row traversal. Second, To accomadate the new traversal the multiply accumulator stores many intermediate $y$ values. Third, we compress the matrix to increase the transfer rate of the matrix from RAM to the FPGA. Together these pillars enable our SpMV implementation to perform competetively with CPUs and GPUs.

%Just as CPU and GPU implementations do, we create a matrix format specific to our implementation. This matrix format mixes column and row traversal for better vector reuse and better compression. Compression effectively increases the memory bandwidth of the FPGA. To enable mixed traversal the multiply accumulator in this implementation accumulates hundreds of rows simultaneously.
