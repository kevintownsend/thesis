\chapter{BACKGROUND}
In its simplest form sparse matrix vector multiplication is the operation $y=Ax$, where A is an $M$ by $N$, $x$ is a vector of length $M$, and $y$ is a vector of length $M$. As Equation 2.1 shows, matrix vector multiplication is a series of dot products.
\begin{equation}
\left[\begin{IEEEeqnarraybox*}[][c]{,c,}
{y_1}\\
{y_2}\\
{y_3}\\
{y_4}\\
{y_5}\\
{y_6}\\
{y_7}\\
{y_8}
\end{IEEEeqnarraybox*}\right]
=
\left[\begin{IEEEeqnarraybox*}[][c]{,c,}
{A_{11}x_1}{+A_{14}x_4}{+A_{17}x_7}\\
{A_{25}x_5}{+A_{28}x_8}\\
{A_{32}x_3}{+A_{33}x_3}{+A_{36}x_6}{+A_{37}x_7}\\
{A_{41}x_1+A_{45}x_5}\\
{A_{53}x_3+A_{54}x_4+A_{57}x_7+A_{58}x_8}\\
{A_{62}x_2+A_{65}x_5}\\
{A_{72}x_2+A_{73}x_3+A_{76}x_6+A_{78}x_8}\\
{A_{83}x_3+A_{84}x_4+A_{85}x_5+A_{86}x_6}
\end{IEEEeqnarraybox*}\right]
=
\left[\begin{IEEEeqnarraybox*}[][c]{,c/c/c/c/c/c/c/c,}
{A_{11}} & 0 & 0 & {A_{14}} & 0 & 0 & {A_{17}} & 0\\
0 & 0 & 0 & 0 & {A_{25}} & 0 & 0 & {A_{28}} \\
0 & {A_{32}} & {A_{33}} & 0 & 0 & {A_{36}} & {A_{37}} & 0 \\
{A_{41}} & 0 & 0 & 0 & {A_{45}} & 0 & 0 & 0\\
0 & 0 & {A_{53}} & {A_{54}} & 0 & 0 & {A_{57}} & {A_{58}}\\
0 & {A_{62}} & 0 & 0 & {A_{65}} & 0 & 0 & 0\\
0 & {A_{72}} & {A_{73}} & 0 & 0 & {A_{76}} & 0 & {A_{78}}\\
0 & 0 & {A_{83}} & {A_{84}} & {A_{85}} & {A_{86}} & 0 & 0
\end{IEEEeqnarraybox*}\right]
\left[\begin{IEEEeqnarraybox*}[][c]{,c,}
{x_1}\\
{x_2}\\
{x_3}\\
{x_4}\\
{x_5}\\
{x_6}\\
{x_7}\\
{x_8}
\end{IEEEeqnarraybox*}\right]
\end{equation}
\par Sparse matrices differ from dense matrices in that they contain mostly (usually more than 99\%) zeros. For example, consider the matrix representation of the Facebook friends graph. Each row contains non-zero values representing friend connections and zero values representing non-friends. Being friends with .1\% of Facebook users would require being friends with 10 million people, an impressive feat. In other words, from the time you started reading this paper 1000 people have joined facebook and are not friends with you. The average user has 300 friends. For this reason sparsity is usually measured in elements per row rather than a percent. The percent sparsity of the matrix keeps growing but the number of non-zero elements per row stays about constant.
\section{Coordinate Formate (COO)}
\par Dense matrices can be stored as an array of values. However if sparse matrices were stored this way they would require orders of magnitude more space than a simple alternative. The alternative, coordinate formate (COO), stores 3 arrays: a row index array, a column index array, and a value array.
Coordinate formate (COO) is the simplest sparse matrix storage scheme. Every non-zero element is stored in 3 parts: a row index, a column index, and the element's value. For simplicity, this paper only concerns itself with double precision values. Using the example matrix, the COO format would be:\\
ROW: 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, \dots 7, 7, 7 \\ \normalsize
COLUMN: 0, 3, 6, 4, 7, 1, 2, 5, \dots 2, 3, 4, 5\\ \normalsize
VALUE: $A_{11}$, $A_{14}$, $A_{17}$, $A_{25}$, $A_{28}$, $A_{32}$, \dots $A_{86}$\\ \normalsize
\indent You will notice that the elements are traversed in row-major form. Row-major traversal starts at the left most element of the first row ($A_{11}$). Then proceeds to the next element to right ($A_{14}$). After arriving at the last element of a row the next element would be the left most element in the row below it ($A_{25}$). This is a convenient, but not necessary traversal of the matrix. 
\par Calculating SpMV with this matrix format is straight forward and much faster than if the whole matrix was used. SpMV takes $nnz$ multiplications and $nnz-M$ additions, where $nnz$ is the number of non-zero values in the matrix and $M$ is the height of the matrix. This totals $2\times nnz - M$ floating point operations. However, the convention in the field uses a slightly incorrect but simpler $2\times nnz$ to report performance, which we use to report our performance. The difference is usually only a slight over estimate of the actual performance, but the difference could be big if $nnz/M$ (number of non-zero elements per row) is small.
\section{CPU Processors}
\par The sparsity of the matrix causes CPUs to perform below their potential. For example Intel publishes an average performance of 200 GFLOPS for matrix matrix multiplication and 50 GFLOPS for matrix vector multiplication but publishes an average performance of 10 GFLOPS for SpMV.
\par To understand this look at the equation 2.1 again and count the number of times each value is accessed. The values in the matrix only get accessed once and the values in the vector only get accessed a couple times. This remains the same for large matrices, because, as mentioned, the number of non-zero values per row ($nnz/M$) often grows slowly for larger matrices. This means the computations to memory operations ratio is low. Compare this to matrix-matrix multiplication where the ratio is high and the CPU can perform at 1 TFLOP, almost the limit of the CPU.
\par The effect of this small ratio effects the CPU less when everything can fit in cache. Although it still exists, because L3 cache has some latency.
\par We would like to cover CPU and GPU optimizations first. We cover techniques and how they could apply to FPGA implementations. If you are impatient feel free to skip ahead to the section about SpMV on the FPGA.
\section{Compressed Sparse Row Format (CSR)}
The first optimization is the simplest. The optimization compresses the row indices. When the elements are traversed in row major form the row indices change little. CSR format stores the first element of each row instead of the row index of each element. The traversal index equals the number of non-zero elements that are traversed before the current element is reached. We use the term traversal index to prevent confusion when mentioning row and column index. Assuming the indices are stored as ints (4 bytes) and values as double (8 byte floating point values) this change saves up to 4 bytes per element or 25\% of the total matrix storage size.
\par Compressed sparse row or CSR is a common compression scheme. It relys on the mentioned row-major traversal. The column and value arrays are the same as COO. A compressed row array replaces the row array. The row array usually doesn't change from one element to the next and when it does it only changes by increasing the index by one. This new compressed row array only marks when the row index is increased by one. The compressed row array for the example is shown: \\
COMPRESSED ROW ARRAY: 3, 5, 9, 11, 15, 17, 21, 25 \normalsize

\begin{figure}
\centering
\begin{tikzpicture}[scale=.6]
\node at (3,6){FPGA0};
\node at (8.5,6){FPGA1};
\node at (14,6){FPGA2};
\node at (19.5,6){FPGA3};
\foreach \x in {1,...,4,5,6.5,7.5,...,10.5,12,13,...,16,17.5,18.5,...,21.5}
    \foreach \y in {1,...,5}
    {
        %\draw (\x, \y) +(-.5,-.5) rectangle ++(.5,.5);
        %\draw (\x, \y) node{\shortstack{$R^3$\\PE}};
        \draw (\x, \y) node{\shortstack{PE}};
    }
\foreach \x in {1.5,2.5,3.5,4.5,7,8,9,10,12.5,13.5,14.5,15.5,18,19,20,21,22}
{
    \path[draw] (\x, .5) -- (\x, 5.5);
}
\foreach \x in {.5,6,11.5,17}
{
    \foreach \y in {1.5,2.5,3.5,4.5}
    \path[draw] (\x, \y) -- (\x+5, \y);
}
\draw (.5,.5) [rounded corners=.2cm]rectangle (5.5,5.5);
\draw (6,.5) [rounded corners=.2cm]rectangle (11,5.5);
\draw (11.5,.5) [rounded corners=.2cm]rectangle (16.5,5.5);
\draw (17,.5) [rounded corners=.2cm]rectangle (22,5.5);
\foreach \x in {3,8.5,14,19.5}{
    \node at (\x, 3)[draw, fill=white, minimum width=1.8cm, minimum height=1.8cm,inner sep=0,outer sep=0]{\shortstack{Shared\\Memory}};
}
\foreach [count=\i] \x in {0,3.3,6.6,...,24}
{
    \FPeval{\minus}{round(\i-1,0)};
    %\draw (\x, -2) +(-.6,-.5) [rounded corners=.2cm] rectangle ++(1.2, .5);
    \small
    \draw (\x, -2) +(.3, 0) node[rectangle,rounded corners=.2cm]{\shortstack{Memory \\Controller\minus}};
    \normalsize
    %\draw (\x, -2) +(.3, 0) node{\shortstack{MC\i}};
}
\foreach \ae in {3, 8.5, 14, 19.5}
{
    \foreach \mc in {.5,3.8,7.1,...,25}
    {
        \draw[thick] (\ae, .5) -- (\mc, -1.5);
    }
}
%\path[draw, dashed] (.5,-.5) -- (18,-.5);
%\node at (9.25,-.5) [rectangle,fill=white,inner sep=2pt](a){40GB/s Sustained Memory Bandwidth};

\end{tikzpicture}
\caption{$R^3$ implementation on the Convey HC-2 coprocessor: 4 Virtex-5 LX330 FPGAs tiled with 16 $R^3$ SpMV processing elements (PE) each. Each Virtex-5 chip connects to all 8 memory controllers, which enables each chip to have access to all of the coprocessor's memory.}
\label{fig:highlevel}
\end{figure}
\begin{table*}
\caption{Matrix Statistics}
\label{matrix_stat}
\centering
\begin{tabular}{ccccccccc}
\hline
\bfseries Matrix & \bfseries Field & \bfseries dimensions & \bfseries nnz & \bfseries nnz/row \\
\hline
 dense & Example & 2,000x2,000 & 4,000,000 & 2,000 \\
consph & FEM/Speres & 83,334x83,334 & 6,010,480 & 72 \\
cant & FEM/Cantilever & 62,451x62,451 & 4,007,383 & 64 \\
rma10 & FEM/Harbor & 46,835x46,835 & 2,329,092 & 49 \\
qcd5\_4 & QCD & 49,152x49,152 & 1,916,928 & 39 \\
shipsec1 & FEM/ship & 140,874x140,874 & 3,568,176 & 25\\
mac\_econ\_fwd500 & Economics & 206,500x206,500 & 1,273,389 & 6.2 \\
mc2depi & Epidemiology & 525,825x525,825 & 2,100,225 & 4.0 \\
scircuit & Circuit & 170,998x170,998 & 958,936 & 5.6 \\
\hline
%webbase-1M & Webbase & 1,000,005x1,000,005 & 3,105,526 & 3.1 & 565 \\
%\hline
\end{tabular}
\end{table*}
\begin{table*}
\caption{Matrix Statistics}
\label{matrix_stat}
\centering
\begin{tabular}{ccccccccc}
\hline
\bfseries Matrix & \bfseries $\bf R^3$ Gflops & \multirow{1}{*}{\bfseries \shortstack{$\bf 2\times$ Intel E5-2690}} & \multirow{1}{*}{\bfseries \shortstack{Nvidia Tesla M2090}}\\
\hline
 dense &  13.6 & 14 & \bf 23\\
consph &  8.7 & 11 & \bf 15\\
cant &  12.7 & 12 & \bf 17\\
rma10 & 13.6 & \bf 24 & 11\\
qcd5\_4 &  12.8 & \bf 30 & 20\\
shipsec1 & 7.9 & 10 &\bf 11\\
mac\_econ\_fwd500 &  5.9 & \bf 23 & 6\\
mc2depi &  6.2 & 21 & \bf 22\\
scircuit &  6.2 & \bf 12 & 6\\
\hline
%webbase-1M & Webbase & 1,000,005x1,000,005 & 3,105,526 & 3.1 & 565 \\
%\hline
\end{tabular}
\end{table*}
\begin{figure*}
\centering
\begin{tikzpicture}[scale=1]

 \ifthenelse{\equal{\blackandwhite}{true}}{
	\tikzstyle{yellowStar}=[draw, diamond, fill=black!65, inner sep =1.5pt];
	\tikzstyle{blueGreenDiamond}=[draw, diamond, fill=black!75, inner sep =1.5pt];
	\tikzstyle{greenSquare}=[draw, rectangle, fill=black!50, inner sep =2.5pt];
	\tikzstyle{blueTriangle}=[draw, regular polygon, regular polygon sides=3, fill=black!35, inner sep =1.5pt];
 }{
	\tikzstyle{yellowStar}=[draw, star, star points=5, fill=yellow, inner sep =1.5pt];
	\tikzstyle{blueGreenDiamond}=[draw, diamond, fill=green!60!blue, inner sep =1.5pt];
	\tikzstyle{greenSquare}=[draw, rectangle, fill=green, inner sep =2.5pt];
	\tikzstyle{blueTriangle}=[draw, regular polygon, regular polygon sides=3, fill=blue, inner sep =1.5pt];
 }

%\draw [ystep=2.0,gray,very thin, xstep = 14] (0,0) grid (12.9, 6.9);
\draw [->,thick] (0,0) to (14.5, 0);
\draw [->, thick] (0,0) to (0,7);
\foreach \x/\mat/\size in { %
0/dw8192/42K, 1/t2d\_q9/87K, 2/epb1/95K, 3/raefsky1/290K, 4/psmigr\_2/540K, 6/torso2/1M%
}
	\draw (\x cm, 1pt) -- (\x cm, -1pt) node[anchor=east,rotate=90,gray] {\shortstack{\mat (\size)}};
\foreach \x/\mat/\size in { %
5/scircuit/960K, 7/mac\_econ/1.3M, 8/qcd5\_4/1.9M, 9/mc2depi/2.1M, 10/rma10/2.3M, 11/shipsec1/3.6M, 12/dense/4M, 13/cant/4M, 14/consph/6M%
}
	\draw (\x cm, 1pt) -- (\x cm, -1pt) node[anchor=east,rotate=90] {\shortstack{\mat (\size)}};
\foreach \y/\ytext in {0/0,1/5,2/10, 3/15, 4/20, 5/25, 6/30}
	\draw (1pt, \y cm) -- (-1pt, \y cm) node[anchor=east] {$\ytext$};
%\node at (6, -.8) {Size of Matrix (Millions)};
\node at (-1, 3) [rotate=90]{Performance (Gflops)};

%R3 line
\foreach \i/\j/\k/\l in {%
0/0.42000000000000004/1/0.76,  1/0.76/2/0.6599999999999999,  2/0.6599999999999999/3/1.04,  3/1.04/4/0.9800000000000001,  4/0.9800000000000001/5/1.24,  5/1.24/6/1.28,  6/1.28/7/1.1800000000000002,  7/1.1800000000000002/8/2.56,  8/2.56/9/1.24,  9/1.24/10/2.7199999999999998,  10/2.7199999999999998/11/1.58,  11/1.58/12/2.7199999999999998,  12/2.7199999999999998/13/2.54,  13/2.54/14/1.7399999999999998
}{
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\draw [black] (\i,\j) -- (\k,\l);
 }{
	\draw [red] (\i,\j) -- (\k,\l);
 }
}

%hc1 line
\foreach \i/\j/\k/\l in {%
0/0.33999999999999997/1/0.5,  1/0.5/2/0.52,  2/0.52/3/0.78,  3/0.78/4/0.78,  4/0.78/6/0.24
}{
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\draw [black!65] (\i,\j) -- (\k,\l);
 }{
	\draw [brown] (\i,\j) -- (\k,\l);
 }
}

%%tesla line
%\foreach \i/\j/\k/\l in {%
%0/0.1/1/0.18,  1/0.18/2/0.16,  2/0.16/3/0.5599999999999999,  3/0.5599/5/0.6}
%	\draw <3,5>[green!60!blue] (\i,\j) -- (\k,\l);

%m2090 line
\foreach \i/\j/\k/\l in {%
5/1.2/7/1.2,  7/1.2/8/4.0,  8/4.0/9/4.4,  9/4.4/10/2.2,  10/2.2/11/2.2,  11/2.2/12/4.6,  12/4.6/13/3.4,  13/3.4/14/3.0
}{
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\draw [black!50] (\i,\j) -- (\k,\l);
 }{
	\draw [green] (\i,\j) -- (\k,\l);
 }
}

%intel line
\foreach \i/\j/\k/\l in {%
5/2.4/7/4.6,  7/4.6/8/6.0,  8/6.0/9/4.2,  9/4.2/10/4.8,  10/4.8/11/2.0,  11/2.0/12/2.8,  12/2.8/13/2.4,  13/2.4/14/2.2
}{
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\draw [black!35] (\i,\j) -- (\k,\l);
 }{
	\draw [blue] (\i,\j) -- (\k,\l);
 }
}


\draw [dashed] (.5, -.5) -- (.5, 7) node [fill=white,inner sep=0pt, midway,below, sloped]{\small $(64K)$};

\draw [dashed] (10.5, -.5) -- (10.5, 7)  node [fill=white,inner sep=0pt, near end,below, sloped]{\small 20MB $(2.5M)$};



%hc1 points
\foreach \i/\x/\y/\f/\q/\u in {%
0/0.083492/0.33999999999999997/1.7/0/-.2,%
1/0.17405/0.5/2.5/0/-.1,%
2/0.190106/0.52/2.6/0/-.2,%
3/0.588552/0.78/3.9/0/-.2,%
4/1.080044/0.78/3.9/0/-.2,%
6/2.066946/0.24/1.2/0/0
}{
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\draw (\i,\y) node[yellowStar]{} node[fill=white,inner sep=0pt, anchor=west,rotate=30,xshift=\q cm + 3pt, yshift=\u cm] {\color{black!65} \scriptsize $\f$};
 }{
	\draw (\i,\y) node[yellowStar]{} node[fill=white,inner sep=0pt, anchor=west,rotate=30,xshift=\q cm + 3pt, yshift=\u cm] {\color{brown} \scriptsize $\f$};
 }
}	

%intel points
\foreach \i/\x/\y/\f/\q/\u in {%
5/1.917872/2.4/12/0/0,%
7/2.546778/4.6/23/0/0,%
8/3.833856/6.0/30/0/0,%
9/4.20045/4.2/21/0/-.2,%
10/4.658184/4.8/24/0/0,%
11/7.136352/2.0/10/0/0,%
12/8.0/2.8/14/0/.2,%
13/8.014766/2.4/12/0/-.2,%
14/12.02096/2.2/11/0/0
}{
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\draw (\i cm,\y cm) node[blueTriangle]{} node[fill=white,inner sep=0pt, anchor=west,rotate=30,xshift=\q cm + 3pt, yshift=\u cm]{\color{black!50} \scriptsize $\f$};
 }{
	\draw (\i cm,\y cm) node[blueTriangle]{} node[fill=white,inner sep=0pt, anchor=west,rotate=30,xshift=\q cm + 3pt, yshift=\u cm]{\color{blue} \scriptsize $\f$};
 }
}

%M2090 points
\foreach \i/\x/\y/\f/\q/\u in {%
5/1.917872/1.2/6/0/-.3,%
7/2.546778/1.2/6/0/.3,%
8/3.833856/4.0/20/0/0,%
9/4.20045/4.4/22/0/0,%
10/4.658184/2.2/11/0/0,%
11/7.136352/2.2/11/0/.1,%
12/8.0/4.6/23/0/0,%
13/8.014766/3.4/17/0/0,%
14/12.02096/3.0/15/0/0
}{
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\draw (\i,\y) node[greenSquare]{} node[fill=white,inner sep=0pt, anchor=west,rotate=30,xshift=\q cm + 3pt, yshift=\u cm]{\color{black!35} \scriptsize $\f$};
 }{
	\draw (\i,\y) node[greenSquare]{} node[fill=white,inner sep=0pt, anchor=west,rotate=30,xshift=\q cm + 3pt, yshift=\u cm]{\color{green!100} \scriptsize $\f$};
 }
}

%R3 points
\foreach \i/\x/\y/\f/\q/\u in {%
0/0.083492/0.42000000000000004/2.1/0/0,%
1/0.17405/0.76/3.8/0/0,%
2/0.190106/0.6599999999999999/3.3/0/0,%
3/0.588552/1.04/5.2/0/0,%
4/1.080044/0.9800000000000001/4.9/0/0,%
5/1.917872/1.24/6.2/0/0,%
6/2.066946/1.28/6.4/0/0,%
7/2.546778/1.1800000000000002/5.9/0/0,%
8/3.833856/2.56/12.8/0/0,%
9/4.20045/1.24/6.2/0/0,%
10/4.658184/2.7199999999999998/13.6/0/0,%
11/7.136352/1.58/7.9/0/0,%
12/8.0/2.7199999999999998/13.6/0/0,%
13/8.014766/2.54/12.7/0/0,%
14/12.02096/1.7399999999999998/8.7/0/0
}{
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\draw (\i,\y) [fill=black]circle(3pt) node(r\i)[fill=white,inner sep=0pt, anchor=west,rotate=30,xshift=\q cm + 3pt, yshift=\u cm]{\color{black} \scriptsize $\f$}; 
 }{
	\draw (\i,\y) [fill=red]circle(3pt) node(r\i)[fill=white,inner sep=0pt, anchor=west,rotate=30,xshift=\q cm + 3pt, yshift=\u cm]{\color{red} \scriptsize $\f$};
 }
}

\draw (4,5.5) node (key)[rectangle,minimum width=4cm, minimum height=2.7cm]{};
 \ifthenelse{\equal{\blackandwhite}{true}}{
	\node at (key) [rectangle,anchor=west, xshift=-2cm, yshift=1cm]{\tikz{\draw (0,1pt) [fill=black]circle (2.5pt);} $R^3$};
 }{
	\node at (key) [rectangle,anchor=west, xshift=-2cm, yshift=1cm]{\tikz{\draw (0,1pt) [fill=red]circle (2.5pt);} $R^3$};
 }
\node at (key) [rectangle,anchor=west, xshift=-2cm, yshift=.3cm]{\shortstack{\tikz{\draw (0,1pt) node[yellowStar]{};} \cite{prelim:nagar1} }};
%\node <3,5>at (key) [rectangle,anchor=west, xshift=-2cm, yshift=0cm]{\tikz{\draw (0,1pt) node[blueGreenDiamond]{};} Nvidia Tesla S1070};
\node at (key) [rectangle,anchor=west, xshift=-2cm, yshift=-.5cm]{\shortstack{\tikz{\draw (0,1pt) node[greenSquare]{};} Nvidia Tesla \\M2090}};
\node at (key) [rectangle,anchor=west, xshift=-2cm, yshift=-1.5cm]{\shortstack{\tikz{\draw (0,1pt) node[blueTriangle]{};} Intel E5-2690 \\(2 CPUs)}};

\end{tikzpicture}
\caption{$nnz$ vs Performance on each platform. The small matrices, ones around 64K or less, performed poorly on $R^3$, due to the overhead. CPUs experience the opposite effect. They take a performance hit once the matrix no longer fits in cache.}
\label{nnzVgflops}
\end{figure*}
\section{Block Sparse Row Format (BSR)}
\par Compression schemes often take advantage of the clumpy structures of sparse matrices. Blocking or register blocking stores dense sub blocks of the matrix together. This again reduces the matrix storage size by storing fewer indices. Some explicit zeros are added to complete the subblocks.
\par The block sparse row (BSR) storage format is one such block storage scheme. It stores the row and column indices of the top left of the block and stores the values of the block in row major form. This matrix format stores the matrix as the some of 2 matrices one in BSR format the other in CSR or COO.
\section{Delta Compression}
\par Another index compression scheme, delta compression, compresses indices aggressively by storing delta distances. A delta is the distance between the previous and current matrix element. The average number of bits to store a delta value is quite small (discussed in chapter 5). cite{prelim:kourtis} is vage on the details, however since this uses variable length encoding some encoding scheme is required. This saves a lot of space, but the results are medicore. The time to decode the deltas into row and column indices requires a non-trivial amount of processing time that potentially could be used for floating point operations. However, FPGAs can dedicate space for decoding, but we will get to that later.
\section{Value Compression}
\par The same paper uses value compression, for the matrix values. Again the details are a little vague, but the idea was to take advantage of the fact values repeat. Eventhough this saves a lot of space for some matrices the results are again mediocore.
\section{Cache Blocking}
\par CPU optimiziations also include changing the matrix traversal for better vector reuse. BSR does this to a small extent. One method called Cache blocking traverses large reletively dense subblocks individually before proceeding to the next block. The dimensions of the block are around the size of available cache. This method has similarities to our row column row (RCR) traversal (Chapter \ref{chapter:compression}).
\section{GPU Processors}
Before discussing storage formats specific to GPUs, it is important to understand GPUs play the computation game differently the CPUs. To show this let us compare a high end CPU (Intel Xeon E5-9999) and a high-end GPU (Nvidia Tesla 9999). The GPU has a max throughput of 1TFLOPS (double precision). The CPU has a max throughput of 200GFLOPS (double precision). The GPU has 1.5MB of cache (although a texture cache is available). The CPU has 20MB of cache. The cache is growing every generation as well. The previous Tesla (Fermi) hat 768KB of cache. The previous Xeon had 15MB of cache. The GPU is a vector machine making it hard to get good performance on unstructured computation.
\par To enable better performance \cite{} used a storage formate designed for vector processors. ELLPACK stores the same number of values for each row. Rows with fewer values than the row with the most values are padded with zeros.\\
\par The ELLPACK formate for the example would be:\\
COLUMN: 0, 3, 6, 0, 4, 7, 0, 0, 1, 2, 5, \dots 2, 3, 4, 5\\ \normalsize
VALUE: $A_{11}$, $A_{14}$, $A_{17}$, $0$, $A_{25}$, $A_{28}$, $0$, $0$, $A_{32}$, \dots $A_{86}$\\ \normalsize
\par The authors also deal with abnormally large rows by computing the values in COO format. Simillar to BSR this stores the matrix into the sum of 2 matrices.
\section{FPGA}
Like GPUs, FPGAs play by their own computation rules. Although FPGAs usually do not have an advertised FLOPS perforamance one can be calculated by creating a matrix matrix multiplication engine to load on the FPGA. (TODO: estimate matrix matrix on virtex 6 and virtex 7).
\par The basic idea of an FPGA is to design the processor you want and that design can be loaded on to an FPGA. Since CPUs and GPUs suffer from bad SpMV performance it seems possible to design a SpMV processor to load on an FPGA and get better performance.
\begin{figure}
\begin{multicols}{3}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/dense}
\caption{dense}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/pdb1HYS}
\caption{pdb1HYS}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/consph}
\caption{consph}
\end{subfigure}
\end{multicols}
\begin{multicols}{3}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/cant}
\caption{cant}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/pwtk}
\caption{pwtk}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/cant}
\caption{cant}
\end{subfigure}
\end{multicols}
\begin{multicols}{3}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/shipsec1}
\caption{shipsec1}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/mac_econ_fwd500}
\caption{mac\_econ\_fwd500}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/cant}
\caption{cant}
\end{subfigure}
\end{multicols}
\begin{multicols}{3}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/cop20k_A}
\caption{cop20k\_A}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/scircuit}
\caption{scircuit}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{images/webbase-1M}
\caption{webbase-1M}
\end{subfigure}
\end{multicols}
\caption{The density plots of the matrices used for testing}
\end{figure}
\section{Reconfigurable Computing Niche}
General purpose hardware (CPUs and GPUs) are undeniably efficient at SpMV. However, CPUs begin to perform badly when the matrices get larger than 20MB, due to slow memory I/O. GPUs can not efficiently handle giant matrices, due to the fact that no commercial GPU card has more than 8GB of ram. SpMV also does not lend itself well to traditional Supercomputing clusters, due to relatively slow interconnect speeds. The next chapter describes our vision of how FPGAs will outperform other processors when it comes to SpMV.
