\chapter{CONCLUSIONS}
\label{chp:conclusion}
This is a lot of work for just a FPGA based SpMV implementation. However we believe SpMV is an important computation and that FPGAs can outperform CPUs and GPUs. As mentioned SpMV with large matrices ($>$ 1 billion values) perform poorly on CPUs because of cache issues and do not fit in the RAM memory of GPU cards. These large matrix applications is where we expect FPGA platforms will be used for SpMV calculations.
\section{Future Work and Predictions}
There are many different avenues for future work and places where this work can be used. The compression ideas presented in this dissertation can be ported to CPUs and may improve performance for very large matrices where external memory bandwidth is an issue (verses matrices that can fit on the 30MB caches CPUs now have). The Convey HC-2ex is outdated and porting this code to another platform would be needed for this work to continue evolving. We believe better tools and software is needed to make HPC FPGA platforms more attractive to users. However, we still believe Verilog and VHDL have more importance than HLS (high-level synthesis) for high performance reconfigurable computing. Ultimately an open source standard needed to create better glue between the software and hardware description language.

Some of this dissertation work also applies to fields not related to SpMV. For example, the decompression hardware that we used for decompression floating point values was very similar to the decompression hardware used for indices. We suspect this may apply to other datasets as well. Having common decompession hardware available on modern CPUs may make compression a more viable option for optimizing memory bound applications, and network bound applications on computing clusters.
%\section{Related Work}
%More information about the work presented in this report is in the following papers:
%\begin{itemize}
%    \item ``A Scalable Unsegmented Multi-port Memory for FPGA-based Systems" (in submission) (paper available on request)
%    \item ``A Multi-Phase Approach to Floating-Point Compression" \cite{prelim:townsend3}
%    \item ``Reduce, Reuse, Recycle ($R^3$): A Design Methodology for Sparse Matrix Vector Multiplication on Reconfigurable Platforms" \cite{prelim:townsend}
%\end{itemize}
%\section{Unrelated Work}
%We have other work done while at the Iowa State Reconfigurable Computing Laboratory, but not present in this report, in the following papers:
%\begin{itemize}
%    \item ``k-NN Text Classification using an FPGA-Based Sparse Matrix Vector Multiplication Accelerator" \cite{prelim:townsend4}
%    \item ``A High Performance Systolic Architecture for k-NN Classification" \cite{prelim:townsend2}
%    \item ``CyGraph: A Reconfigurable Architecture for Parallel Breadth-First Search" \cite{prelim:attia}
%    \item ``A 15-bit Binary-Weighted Current-Steering DAC with Order Element Matching" \cite{prelim:zeng}
%    \item ``Shepard: A Fast Exact Match Short Read Aligner" \cite{prelim:nelson}
%\end{itemize}
