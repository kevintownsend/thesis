\chapter{CONCLUSIONS}
\label{chp:conclusion}
Achieving high performance SpMV on FPGAs requires optimizing several different problems. However we believe SpMV is an important computation and that FPGAs can outperform CPUs and GPUs in certain situations. As mentioned SpMV with large matrices ($>$ 1 billion values) perform poorly on CPUs because of cache issues and do not fit in the RAM memory of GPU cards. These large matrix applications is where we expect FPGA platforms will be used for SpMV calculations.
\section{Future Work}
There are many different avenues for future work and places where this work can be used. The compression ideas presented in this dissertation can be ported to CPUs and may improve performance for very large matrices where external memory bandwidth is an issue (verses matrices that can fit on the 30MB caches CPUs now have). The Convey HC-2ex is dated and porting this code to another platform would allow this work to continue evolving.

Some of this dissertation work also applies to fields not related to SpMV. For example, the decompression hardware that we used for decompression floating point values was very similar to the decompression hardware used for indices. We suspect this may apply to other datasets as well. Having common decompression hardware available on modern CPUs may make compression a more viable option for optimizing memory bound applications, and network bound applications on computing clusters.
%\section{Related Work}
%More information about the work presented in this report is in the following papers:
%\begin{itemize}
%    \item ``A Scalable Unsegmented Multi-port Memory for FPGA-based Systems" (in submission) (paper available on request)
%    \item ``A Multi-Phase Approach to Floating-Point Compression" \cite{prelim:townsend3}
%    \item ``Reduce, Reuse, Recycle ($R^3$): A Design Methodology for Sparse Matrix Vector Multiplication on Reconfigurable Platforms" \cite{prelim:townsend}
%\end{itemize}
%\section{Unrelated Work}
%We have other work done while at the Iowa State Reconfigurable Computing Laboratory, but not present in this report, in the following papers:
%\begin{itemize}
%    \item ``k-NN Text Classification using an FPGA-Based Sparse Matrix Vector Multiplication Accelerator" \cite{prelim:townsend4}
%    \item ``A High Performance Systolic Architecture for k-NN Classification" \cite{prelim:townsend2}
%    \item ``CyGraph: A Reconfigurable Architecture for Parallel Breadth-First Search" \cite{prelim:attia}
%    \item ``A 15-bit Binary-Weighted Current-Steering DAC with Order Element Matching" \cite{prelim:zeng}
%    \item ``Shepard: A Fast Exact Match Short Read Aligner" \cite{prelim:nelson}
%\end{itemize}
