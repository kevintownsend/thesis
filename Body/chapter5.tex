\chapter{MATRIX COMPRESSION}
\label{chp:compression}
Although we address this pillar last we view it as the most important.
\section{Related Work}
We previously implemented matrix compression in \cite{}. However, we made the mistake of combining the two types of compression, index and floating point into one scheme. This simplified some aspects of the design. For example, this compression only needed to keep track of one data stream. Combining the two parts also makes sense if the two are correlated. In the extreme case the values in matrix could be calculated from the indices. However, we do not see an easy way to use this for general sparse matrix compression.

All other work treat index compression and floating point compression seperately and most work ignores floating point compression completely. We also use general compression programs like gzip and bzip for comparison.

%TODO: other works
%
%The two delta streams.
%
%gzip
%
%bzip
%
%microsoft
%
%bakos
%
%others
%
%As we mentioned we also treat index compression seperately.

Not much work focuses solely on matrix compression. However, matrix compression for SpMV has been studied. Most approaches split the problem into matrix index compression and value compression. We agree with this approach. In $R^3$, we made the mistake of combining the indices and values of sparse matrices into one compression scheme. 
\par We discuss floating point value compression in the next chapter. In this chapter we discuss index compression, but first we discuss matrix traversal. \par
This chapter will show matrix traversal and index compression are linked. We use deltas to compress indices. In $R^3$ we use a traversal called global row major local column major (GRMLCM). For the rest of the paper we call this traversal column row traversal, which we discussed in Section~\ref{sec:colrow}. \par
%\begin{table*}
%\centering
%\begin{threeparttable}
%\caption{General information on test matrices and performance of previous compression methods}
%\label{tbl:analysis}
%\begin{tabular}{cccccccccc}
%\hline
%\bfseries Matrix & \bfseries \shortstack{COO\\(bytes/nnz)} & \bfseries \shortstack{CSR\\(bytes/nnz)} & \bfseries COO+gzip &\bfseries CSR+gzip & \bfseries $R^3$ Format \\
% \\
%\hline
%dense2\tnote{a} &  $16.00$ & $12.06$ & $0.85$ & $0.51$ & $2.27$ \\
%pdb1HYS & $16.00$ & $12.15$ & $7.55$ & $6.68$ & $9.60$ \\
%consph & $16.00$ & $12.65$ & $3.23$ & $2.21$ & $7.60$ \\
%cant &  $16.00$ & $12.03$ & $4.39$ & $4.32$ & $9.13$ \\
%pwtk &  $16.00$ & $12.10$ & $0.55$ & $0.32$ & $2.58$ \\
%rma10\tnote{a} &  $16.00$ & $12.71$ & $4.67$ & $3.56$ & $5.82$ \\
%qcd5\_4\tnote{a} &$16.00$ & $12.06$ & $5.43$ & $5.42$ & $9.11$ \\
%shipsec1 &  $16.00$ & $12.00$ & $0.06$ & $0.04$ & $2.26$ \\
%mac\_econ\_fwd500 &  $16.00$ & $13.00$ & $4.09$ & $3.01$ & $5.46$ \\
%mc2depi &  $16.00$ & $12.08$ & $4.57$ & $4.46$ & $8.81$ \\
%cop20k\_A &  $16.00$ & $12.08$ & $0.35$ & $0.21$ & $2.46$ \\
%scircuit & $16.00$ & $12.16$ & $3.68$ & $2.92$ & $7.19$ \\
%webbase-1M & $16.00$ & $13.29$ & $2.18$ & $1.73$ & $2.64$ \\
%\hline
%average\tnote{b} &  $16.00$ & $12.34$ & $3.20$ & $2.72$ & $5.76$ \\
%
%\hline
%\end{tabular}
%\begin{tablenotes}
%\item [a] Boolean matrices
%\item [b] Excludes boolean matrices (TODO)
%\end{tablenotes}
%\end{threeparttable}
%\end{table*}
At this point we have a traversal that abides by the rules needed for the multiply accumulator and reuses vector values. However, no thought has yet been given to compression. To better understand compression we analyze several compression schemes.
\section{Delta Compression}
\begin{table*}
\centering
\begin{threeparttable}
\caption{Detailed analysis of index compression}
\label{tbl:index}
\begin{tabular}{cccccccc}
\hline
\bfseries Matrix & \bfseries \tikz \node[rotate=90]{COO}; & \bfseries \tikz \node[rotate=90]{CSR}; & \bfseries \tikz \node[rotate=90]{CSR.gz}; & \bfseries \tikz \node[rotate=90]{Row major\tnote{b}}; & \bfseries \tikz \node[rotate=90]{Column row-16\tnote{b}}; & \bfseries \tikz \node[rotate=90]{Column row-256\tnote{b}}; & \bfseries \tikz \node [rotate=90]{Column row-1024\tnote{b}};  \\
\hline
dense2 & 8.00 & 4.00 & 0.03 & 0.00 & 0.00 & 0.00 & 0.00 \\
pdb1HYS & 8.00 & 4.03 & 0.14 & 0.06 & 0.05 & 0.05 & 0.06 \\
consph & 8.00 & 4.06 & 0.19 & 0.13 & 0.10 & 0.11 & 0.12 \\
cant & 8.00 & 4.06 & 0.40 & 0.12 & 0.10 & 0.11 & 0.11 \\
pwtk & 8.00 & 4.08 & 0.17 & 0.09 & 0.05 & 0.06 & 0.07 \\
rma10\ & 8.00 & 4.08 & 0.20 & 0.11 & 0.08 & 0.09 & 0.10 \\
qcd5\_4 & 8.00 & 4.10 & 0.31 & 0.24 & 0.16 & 0.20 & 0.22 \\
shipsec1 & 8.00 & 4.16 & 0.86 & 0.41 & 0.27 & 0.34 & 0.37 \\
mac\_econ\_fwd500 & 8.00 & 4.65 & 1.48 & 0.77 & 0.56 & 0.61 & 0.64 \\
mc2depi & 8.00 & 5.00 & 1.78 & 1.11 & 0.50 & 0.81 & 0.88 \\
cop20k\_A & 8.00 & 4.15 & 1.07 & 0.58 & 0.42 & 0.49 & 0.53 \\
scircuit & 8.00 & 4.71 & 1.61 & 0.85 & 0.48 & 0.58 & 0.66 \\
webbase-1M & 8.00 & 5.29 & 1.35 & 1.57 & 0.46 & 0.55 & 0.64 \\
\hline
average\tnote{a} & 8.00 & 4.36 & 0.80 & 0.50 & 0.27 & 0.33 & 0.37 \\

\hline
\end{tabular}
\begin{tablenotes}
\item [a] Excludes dense matrix
\item [b] Only counting delta bits.
\end{tablenotes}
\end{threeparttable}
\end{table*}

Many papers use delta compression \cite{prelim:townsend, prelim:kourtis, prelim:kestur}. Delta compression stores the distance between the previous and current element. This results in smaller values that require fewer bits. The overhead of encoding the bit lengths varies among the different schemes. The storage size per element of these delta values using only the bits necessary are in column 5 of Table~\ref{tbl:index} (this does not include overhead).\par
We also choose to use the general compression program gzip in the comparison as well. Again table \ref{tbl:index} shows the compression of gzip on top of the CSR format. gzip does very well, in one case (webbase-1M) even takes less space than storing only delta bits. This is particularly surprising considering that extra overhead is needed to decode these delta bits. The reason this occurs is because large delta values can represent a short vertical jump. (We start to see the disadvantage of row major traversal.) gzip remembers previous column indexes and therefore can compress them easily.\par
\begin{sidewaystable}
\centering
\begin{threeparttable}
    \caption[The distribution of deltas by bit length]{The distribution of the bit lengths required to store the delta length when using column row-16 traversal}
\label{tbl:indexDist}
\begin{tabular}{cccccccccccc}
\hline
\bfseries Matrix & \bfseries 1 & \bfseries 2 & \bfseries 3-4 & \bfseries 5-8 & \bfseries 9-16 & \bfseries 17-32 & \bfseries 33-64 &\bfseries 65-128 & \bfseries 129-256 & \bfseries 257-512 & \bfseries 512+\\
\hline
dense2 & 100.00\% & 0.00\% & 0.00\% & 0.00\% & 0.00\% & 0.00\% & 0.00\% & 0.00\% & 0.00\% & 0.00\% & 0.00\% \\
pdb1HYS & 89.23\% & 0.44\% & 2.39\% & 2.43\% & 4.77\% & 0.01\% & 0.19\% & 0.09\% & 0.13\% & 0.05\% & 0.26\% \\
consph & 80.47\% & 1.58\% & 0.03\% & 3.30\% & 12.89\% & 0.71\% & 0.02\% & 0.00\% & 0.00\% & 0.48\% & 0.52\% \\
cant & 75.74\% & 5.43\% & 0.08\% & 2.99\% & 14.34\% & 0.58\% & 0.40\% & 0.12\% & 0.02\% & 0.01\% & 0.29\% \\
pwtk & 87.88\% & 1.49\% & 1.25\% & 3.07\% & 5.87\% & 0.04\% & 0.01\% & 0.00\% & 0.00\% & 0.01\% & 0.38\% \\
rma10 & 81.63\% & 0.52\% & 4.43\% & 4.17\% & 7.66\% & 0.15\% & 0.56\% & 0.18\% & 0.07\% & 0.09\% & 0.53\% \\
qcd5\_4 & 67.63\% & 0.11\% & 3.85\% & 7.10\% & 17.36\% & 2.62\% & 0.00\% & 0.21\% & 0.00\% & 0.00\% & 1.12\% \\
shipsec1 & 40.79\% & 11.53\% & 7.76\% & 3.74\% & 23.43\% & 9.51\% & 0.40\% & 0.45\% & 0.24\% & 0.36\% & 1.81\% \\
mac\_econ\_fwd500 & 16.16\% & 3.98\% & 11.35\% & 7.30\% & 15.28\% & 12.42\% & 9.75\% & 6.41\% & 6.05\% & 3.77\% & 7.52\% \\
mc2depi & 23.36\% & 0.00\% & 0.00\% & 0.01\% & 24.92\% & 47.00\% & 0.02\% & 0.00\% & 0.00\% & 0.01\% & 4.68\% \\
cop20k\_A & 50.18\% & 2.14\% & 1.55\% & 1.83\% & 24.16\% & 2.65\% & 1.11\% & 1.10\% & 1.07\% & 0.95\% & 13.26\% \\
scircuit & 37.71\% & 3.00\% & 2.71\% & 2.62\% & 25.65\% & 8.14\% & 3.45\% & 2.71\% & 2.27\% & 1.51\% & 10.24\% \\
webbase-1M & 46.55\% & 2.40\% & 1.70\% & 1.27\% & 5.57\% & 30.67\% & 0.74\% & 0.50\% & 0.36\% & 0.25\% & 9.99\% \\
\hline
average\tnote{a} & 58.11\% & 2.72\% & 3.09\% & 3.32\% & 15.16\% & 9.54\% & 1.39\% & 0.98\% & 0.85\% & 0.62\% & 4.22\% \\
\hline
\end{tabular}
\begin{tablenotes}
\item [a] Excludes dense matrix
\end{tablenotes}
\end{threeparttable}
\end{sidewaystable}%
It seems hard to believe that gzip would be the best compression scheme. However, we notice column row traversal has smaller deltas than row major traversal. The Table~\ref{tbl:indexDist} shows this distribution. This is because column row traversal does make vertical steps.
\section{Encoding Deltas}
However, it does not fix the issue that extra overhead is needed to decode the delta bits. We need to create our own encoding scheme. The rest of this section describes this encoding scheme. To reduce the overhead we will use a variable sized encoding scheme. We looked at the distribution of bit lengths over all the matrices in the test cases. \par

%TODO: split index and value analysis
%COO (indicies only), CSR, COO+gz, CSR+gz, delta, delta+gz, R3, R3+gz, values only, 256 mc, 66k mc var index, fpc


One of the easiest trend to see from the distribution of bits in Table \ref{tbl:index} is that most deltas are less than 32.% TODO: describe sceme.
%\section{Hardware Decoding}
%\label{sec:fzipdecoder}
%We choose this compression scheme with decompression in mind. The decoding must decode the Huffman encoded stream and the argument (not-encoded) stream. Our design has 3 parts: first, decoding the Huffman codes, second, retrieving an argument if needed, and third, converting the delta codes into matrix indices.
%\subsection{Huffman Decoder}
%To understand our huffman decoder let us assume all the codes 
%\section{Results}
